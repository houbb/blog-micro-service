---
title: Using Docker Logs and Diagnostic Tools - Mastering Container Observability and Analysis
date: 2025-08-31
categories: [Docker]
tags: [docker, logs, diagnostics, observability, containers]
published: true
---

## ä½¿ç”¨ Docker çš„æ—¥å¿—ä¸è¯Šæ–­å·¥å…·

### æ—¥å¿—ç®¡ç†åŸºç¡€

æœ‰æ•ˆçš„æ—¥å¿—ç®¡ç†æ˜¯å®¹å™¨åŒ–åº”ç”¨è¿ç»´çš„æ ¸å¿ƒç»„æˆéƒ¨åˆ†ã€‚Docker æä¾›äº†å¤šç§æ—¥å¿—é©±åŠ¨å’Œå·¥å…·ï¼Œå¸®åŠ©ç”¨æˆ·æ”¶é›†ã€åˆ†æå’Œç›‘æ§å®¹å™¨æ—¥å¿—ã€‚

#### æ—¥å¿—é©±åŠ¨ç±»å‹

1. **json-file**ï¼šé»˜è®¤é©±åŠ¨ï¼Œå°†æ—¥å¿—ä¿å­˜ä¸º JSON æ ¼å¼
2. **syslog**ï¼šå°†æ—¥å¿—å‘é€åˆ° syslog æœåŠ¡å™¨
3. **journald**ï¼šå°†æ—¥å¿—å‘é€åˆ° systemd journald
4. **gelf**ï¼šå°†æ—¥å¿—å‘é€åˆ° GELF å…¼å®¹çš„æ—¥å¿—æ”¶é›†å™¨
5. **fluentd**ï¼šå°†æ—¥å¿—å‘é€åˆ° Fluentd
6. **awslogs**ï¼šå°†æ—¥å¿—å‘é€åˆ° AWS CloudWatch Logs

### åŸºç¡€æ—¥å¿—æ“ä½œ

#### æŸ¥çœ‹æ—¥å¿—

```bash
# æŸ¥çœ‹å®¹å™¨æ—¥å¿—
docker logs <container_name>

# å®æ—¶æŸ¥çœ‹æ—¥å¿—
docker logs -f <container_name>

# æŸ¥çœ‹æœ€è¿‘çš„æ—¥å¿—è¡Œæ•°
docker logs --tail 100 <container_name>

# æŸ¥çœ‹æŒ‡å®šæ—¶é—´åçš„æ—¥å¿—
docker logs --since="2023-01-01T00:00:00" <container_name>

# æŸ¥çœ‹æŒ‡å®šæ—¶é—´èŒƒå›´çš„æ—¥å¿—
docker logs --since="1h" --until="30m" <container_name>

# æŸ¥çœ‹å¸¦æ—¶é—´æˆ³çš„æ—¥å¿—
docker logs -t <container_name>
```

#### æ—¥å¿—æ ¼å¼åŒ–è¾“å‡º

```bash
# ä½¿ç”¨æ¨¡æ¿æ ¼å¼åŒ–æ—¥å¿—è¾“å‡º
docker logs --format "{{.Timestamp}} {{.Message}}" <container_name>

# æŸ¥çœ‹è¯¦ç»†æ—¥å¿—ä¿¡æ¯
docker logs --details <container_name>
```

### é«˜çº§æ—¥å¿—é…ç½®

#### é…ç½®æ—¥å¿—é©±åŠ¨

```bash
# ä½¿ç”¨ json-file é©±åŠ¨ï¼ˆé»˜è®¤ï¼‰
docker run -d --name web nginx

# æŒ‡å®šæ—¥å¿—é©±åŠ¨å’Œé€‰é¡¹
docker run -d --name web \
  --log-driver json-file \
  --log-opt max-size=10m \
  --log-opt max-file=3 \
  nginx

# ä½¿ç”¨ syslog é©±åŠ¨
docker run -d --name web \
  --log-driver syslog \
  --log-opt syslog-address=tcp://192.168.1.42:123 \
  nginx

# ä½¿ç”¨ fluentd é©±åŠ¨
docker run -d --name web \
  --log-driver fluentd \
  --log-opt fluentd-address=192.168.1.42:24224 \
  --log-opt tag=docker.web \
  nginx
```

#### å…¨å±€æ—¥å¿—é…ç½®

```json
// /etc/docker/daemon.json
{
  "log-driver": "json-file",
  "log-opts": {
    "max-size": "10m",
    "max-file": "3",
    "labels": "production_status",
    "env": "os,customer"
  }
}
```

### æ—¥å¿—è½®è½¬å’Œæ¸…ç†

#### é…ç½®æ—¥å¿—è½®è½¬

```json
// å®¹å™¨ç‰¹å®šçš„æ—¥å¿—è½®è½¬é…ç½®
{
  "log-driver": "json-file",
  "log-opts": {
    "max-size": "100m",
    "max-file": "10"
  }
}
```

#### æ‰‹åŠ¨æ—¥å¿—æ¸…ç†

```bash
# æŸ¥çœ‹æ—¥å¿—æ–‡ä»¶å¤§å°
docker inspect web | grep LogPath
ls -lh $(docker inspect web | grep LogPath | cut -d'"' -f4)

# æ¸…ç†ç‰¹å®šå®¹å™¨çš„æ—¥å¿—
echo "" > $(docker inspect web | grep LogPath | cut -d'"' -f4)

# æ‰¹é‡æ¸…ç†åœæ­¢å®¹å™¨çš„æ—¥å¿—
docker ps -aq | xargs -I {} sh -c 'echo "" > $(docker inspect {} | grep LogPath | cut -d"\"" -f4)'
```

### é›†ä¸­å¼æ—¥å¿—ç®¡ç†

#### ä½¿ç”¨ ELK Stack

```yaml
# docker-compose.logging.yml
version: '3.8'

services:
  elasticsearch:
    image: elasticsearch:7.17.0
    environment:
      - discovery.type=single-node
      - ES_JAVA_OPTS=-Xms1g -Xmx1g
    ports:
      - "9200:9200"
      - "9300:9300"
    volumes:
      - es_data:/usr/share/elasticsearch/data

  logstash:
    image: logstash:7.17.0
    ports:
      - "5000:5000"
      - "9600:9600"
    volumes:
      - ./logstash/pipeline:/usr/share/logstash/pipeline
    depends_on:
      - elasticsearch

  kibana:
    image: kibana:7.17.0
    ports:
      - "5601:5601"
    depends_on:
      - elasticsearch

volumes:
  es_data:
```

```ruby
# logstash/pipeline/logstash.conf
input {
  gelf {
    port => 12201
  }
}

filter {
  if [log][file][path] {
    mutate {
      add_field => { "filename" => "%{[log][file][path]}" }
    }
  }
  
  grok {
    match => { "message" => "%{TIMESTAMP_ISO8601:timestamp} \[%{DATA:service}\] %{LOGLEVEL:level}: %{GREEDYDATA:message}" }
  }
  
  date {
    match => [ "timestamp", "ISO8601" ]
  }
}

output {
  elasticsearch {
    hosts => ["elasticsearch:9200"]
    index => "docker-logs-%{+YYYY.MM.dd}"
  }
  
  stdout {
    codec => rubydebug
  }
}
```

#### é…ç½®åº”ç”¨å®¹å™¨å‘é€æ—¥å¿—åˆ° ELK

```bash
# ä½¿ç”¨ gelf é©±åŠ¨å‘é€æ—¥å¿—åˆ° Logstash
docker run -d --name web \
  --log-driver gelf \
  --log-opt gelf-address=udp://localhost:12201 \
  nginx
```

### è¯Šæ–­å·¥å…·

#### Docker åŸç”Ÿè¯Šæ–­å·¥å…·

```bash
# æŸ¥çœ‹ Docker ç³»ç»Ÿä¿¡æ¯
docker system info

# æŸ¥çœ‹ç£ç›˜ä½¿ç”¨æƒ…å†µ
docker system df

# æŸ¥çœ‹è¯¦ç»†ç£ç›˜ä½¿ç”¨æƒ…å†µ
docker system df -v

# æŸ¥çœ‹ Docker äº‹ä»¶
docker events

# æŸ¥çœ‹ç‰¹å®šæ—¶é—´èŒƒå›´çš„äº‹ä»¶
docker events --since "1h"

# æŸ¥çœ‹ç‰¹å®šå®¹å™¨çš„äº‹ä»¶
docker events --filter container=myapp
```

#### ä½¿ç”¨ ctop å·¥å…·

```bash
# å®‰è£… ctop
sudo wget https://github.com/bcicen/ctop/releases/download/v0.7.7/ctop-0.7.7-linux-amd64 -O /usr/local/bin/ctop
sudo chmod +x /usr/local/bin/ctop

# è¿è¡Œ ctop
ctop

# ä½¿ç”¨ç‰¹å®š Docker ä¸»æœº
ctop -H tcp://remote-host:2375

# åªæ˜¾ç¤ºè¿è¡Œä¸­çš„å®¹å™¨
ctop -a
```

#### ä½¿ç”¨ dive åˆ†æé•œåƒ

```bash
# å®‰è£… dive
wget https://github.com/wagoodman/dive/releases/download/v0.10.0/dive_0.10.0_linux_amd64.deb
sudo apt install ./dive_0.10.0_linux_amd64.deb

# åˆ†æé•œåƒ
dive myapp:latest

# æ‰¹é‡åˆ†æé•œåƒ
dive myapp:v1.0 myapp:v1.1 myapp:v1.2
```

### æ€§èƒ½è¯Šæ–­å·¥å…·

#### ä½¿ç”¨ docker stats

```bash
# æŸ¥çœ‹å•ä¸ªå®¹å™¨çš„èµ„æºä½¿ç”¨æƒ…å†µ
docker stats web

# æŸ¥çœ‹æ‰€æœ‰å®¹å™¨çš„èµ„æºä½¿ç”¨æƒ…å†µ
docker stats

# é™åˆ¶è¾“å‡ºçš„å®¹å™¨
docker stats web db redis

# æ ¼å¼åŒ–è¾“å‡º
docker stats --format "table {{.Container}}\t{{.CPUPerc}}\t{{.MemUsage}}\t{{.NetIO}}\t{{.BlockIO}}"
```

#### ä½¿ç”¨ sysdig

```bash
# å®‰è£… sysdig
curl -s https://s3.amazonaws.com/download.draios.com/stable/install-sysdig | sudo bash

# ç›‘æ§å®¹å™¨ç³»ç»Ÿè°ƒç”¨
sudo sysdig -pc container.name=web

# æŸ¥çœ‹å®¹å™¨ç½‘ç»œæ´»åŠ¨
sudo sysdig -pc -c topprocs_net container.name=web

# æŸ¥çœ‹å®¹å™¨æ–‡ä»¶ I/O
sudo sysdig -pc -c topfiles_bytes container.name=web
```

### è‡ªå®šä¹‰è¯Šæ–­è„šæœ¬

#### å®¹å™¨å¥åº·æ£€æŸ¥è„šæœ¬

```bash
#!/bin/bash
# health-checker.sh

# å®¹å™¨å¥åº·æ£€æŸ¥è„šæœ¬
CONTAINERS=("web" "db" "redis")
THRESHOLD_CPU=80
THRESHOLD_MEM=80

echo "=== å®¹å™¨å¥åº·æ£€æŸ¥æŠ¥å‘Š $(date) ==="

for container in "${CONTAINERS[@]}"; do
    echo "--- å®¹å™¨: $container ---"
    
    # æ£€æŸ¥å®¹å™¨æ˜¯å¦è¿è¡Œ
    if ! docker ps --format "{{.Names}}" | grep -q "^${container}$"; then
        echo "âŒ å®¹å™¨æœªè¿è¡Œ"
        continue
    fi
    
    # è·å–èµ„æºä½¿ç”¨æƒ…å†µ
    cpu_usage=$(docker stats --no-stream --format "{{.CPUPerc}}" $container | sed 's/%//')
    mem_usage=$(docker stats --no-stream --format "{{.MemPerc}}" $container | sed 's/%//')
    
    echo "CPU ä½¿ç”¨ç‡: ${cpu_usage}%"
    echo "å†…å­˜ä½¿ç”¨ç‡: ${mem_usage}%"
    
    # æ£€æŸ¥ CPU ä½¿ç”¨ç‡
    if (( $(echo "$cpu_usage > $THRESHOLD_CPU" | bc -l) )); then
        echo "âš ï¸  è­¦å‘Š: CPU ä½¿ç”¨ç‡è¿‡é«˜"
    fi
    
    # æ£€æŸ¥å†…å­˜ä½¿ç”¨ç‡
    if (( $(echo "$mem_usage > $THRESHOLD_MEM" | bc -l) )); then
        echo "âš ï¸  è­¦å‘Š: å†…å­˜ä½¿ç”¨ç‡è¿‡é«˜"
    fi
    
    # æ£€æŸ¥åº”ç”¨å¥åº·ç«¯ç‚¹
    if docker exec $container curl -f http://localhost:80/health > /dev/null 2>&1; then
        echo "âœ… åº”ç”¨å¥åº·æ£€æŸ¥é€šè¿‡"
    else
        echo "âŒ åº”ç”¨å¥åº·æ£€æŸ¥å¤±è´¥"
    fi
    
    echo ""
done
```

#### ç³»ç»Ÿèµ„æºç›‘æ§è„šæœ¬

```bash
#!/bin/bash
# system-monitor.sh

# ç³»ç»Ÿèµ„æºç›‘æ§è„šæœ¬
echo "=== Docker ç³»ç»Ÿç›‘æ§æŠ¥å‘Š $(date) ==="

# Docker ç³»ç»Ÿä¿¡æ¯
echo "--- Docker ç³»ç»Ÿä¿¡æ¯ ---"
docker info | grep -E "Server Version|Storage Driver|Logging Driver|Kernel Version"

# ç£ç›˜ä½¿ç”¨æƒ…å†µ
echo ""
echo "--- ç£ç›˜ä½¿ç”¨æƒ…å†µ ---"
docker system df

# è¿è¡Œä¸­çš„å®¹å™¨
echo ""
echo "--- è¿è¡Œä¸­çš„å®¹å™¨ ---"
docker ps --format "table {{.Names}}\t{{.Image}}\t{{.Status}}\t{{.Ports}}"

# èµ„æºä½¿ç”¨æƒ…å†µ
echo ""
echo "--- èµ„æºä½¿ç”¨æƒ…å†µ ---"
docker stats --no-stream --format "table {{.Container}}\t{{.CPUPerc}}\t{{.MemPerc}}\t{{.NetIO}}"

# æœ€è¿‘çš„äº‹ä»¶
echo ""
echo "--- æœ€è¿‘çš„äº‹ä»¶ ---"
docker events --since "1h" --until "0s" | tail -10
```

#### ç½‘ç»œè¯Šæ–­è„šæœ¬

```bash
#!/bin/bash
# network-diagnostic.sh

# ç½‘ç»œè¯Šæ–­è„šæœ¬
CONTAINER_NAME="$1"

if [ -z "$CONTAINER_NAME" ]; then
    echo "ç”¨æ³•: $0 <container_name>"
    exit 1
fi

echo "=== ç½‘ç»œè¯Šæ–­æŠ¥å‘Š: $CONTAINER_NAME ==="
echo "æ—¶é—´: $(date)"
echo ""

# æ£€æŸ¥å®¹å™¨ç½‘ç»œé…ç½®
echo "--- å®¹å™¨ç½‘ç»œé…ç½® ---"
docker inspect $CONTAINER_NAME | jq '.[0].NetworkSettings'

# è·å–å®¹å™¨ IP
CONTAINER_IP=$(docker inspect $CONTAINER_NAME | jq -r '.[0].NetworkSettings.IPAddress')
echo "å®¹å™¨ IP: $CONTAINER_IP"

# æµ‹è¯•ç½‘ç»œè¿é€šæ€§
echo ""
echo "--- ç½‘ç»œè¿é€šæ€§æµ‹è¯• ---"
docker exec $CONTAINER_NAME ping -c 4 127.0.0.1
docker exec $CONTAINER_NAME ping -c 4 $CONTAINER_IP

# æµ‹è¯•å¤–éƒ¨è¿æ¥
echo ""
echo "--- å¤–éƒ¨è¿æ¥æµ‹è¯• ---"
docker exec $CONTAINER_NAME ping -c 4 8.8.8.8

# æµ‹è¯• DNS è§£æ
echo ""
echo "--- DNS è§£ææµ‹è¯• ---"
docker exec $CONTAINER_NAME nslookup google.com

# æŸ¥çœ‹ç½‘ç»œæ¥å£
echo ""
echo "--- ç½‘ç»œæ¥å£ä¿¡æ¯ ---"
docker exec $CONTAINER_NAME ip addr

# æŸ¥çœ‹è·¯ç”±è¡¨
echo ""
echo "--- è·¯ç”±è¡¨ ---"
docker exec $CONTAINER_NAME ip route

# æŸ¥çœ‹ç«¯å£ç›‘å¬
echo ""
echo "--- ç«¯å£ç›‘å¬æƒ…å†µ ---"
docker exec $CONTAINER_NAME ss -tulpn
```

### æ—¥å¿—åˆ†æå·¥å…·

#### ä½¿ç”¨ Logstash è¿›è¡Œæ—¥å¿—åˆ†æ

```bash
# å®‰è£… Logstash
curl -L -O https://artifacts.elastic.co/downloads/logstash/logstash-7.17.0-linux-x86_64.tar.gz
tar -xzf logstash-7.17.0-linux-x86_64.tar.gz

# åˆ›å»ºæ—¥å¿—åˆ†æé…ç½®
cat > log-analysis.conf << EOF
input {
  file {
    path => "/var/lib/docker/containers/*/*.log"
    start_position => "beginning"
    sincedb_path => "/dev/null"
    codec => "json"
  }
}

filter {
  # è§£æ Docker æ—¥å¿—
  json {
    source => "message"
    target => "docker"
  }
  
  # æ·»åŠ æ—¶é—´æˆ³
  date {
    match => [ "docker.time", "ISO8601" ]
  }
  
  # è§£æåº”ç”¨æ—¥å¿—
  grok {
    match => { "docker.log" => "%{TIMESTAMP_ISO8601:timestamp} \[%{DATA:service}\] %{LOGLEVEL:level}: %{GREEDYDATA:message}" }
  }
}

output {
  # è¾“å‡ºåˆ° Elasticsearch
  elasticsearch {
    hosts => ["localhost:9200"]
    index => "app-logs-%{+YYYY.MM.dd}"
  }
  
  # è¾“å‡ºåˆ°æ ‡å‡†è¾“å‡º
  stdout {
    codec => rubydebug
  }
}
EOF

# è¿è¡Œ Logstash
./bin/logstash -f log-analysis.conf
```

#### ä½¿ç”¨ Fluentd è¿›è¡Œæ—¥å¿—æ”¶é›†

```bash
# åˆ›å»º Fluentd é…ç½®
cat > fluentd.conf << EOF
<source>
  @type forward
  port 24224
  bind 0.0.0.0
</source>

<source>
  @type http
  port 9880
  bind 0.0.0.0
</source>

<filter docker.**>
  @type parser
  key_name log
  reserve_data true
  <parse>
    @type json
  </parse>
</filter>

<match docker.**>
  @type elasticsearch
  host elasticsearch
  port 9200
  logstash_format true
  logstash_prefix docker
  logstash_dateformat %Y%m%d
  include_tag_key true
  type_name access_log
  tag_key @log_name
  flush_interval 1s
</match>
EOF

# è¿è¡Œ Fluentd
fluentd -c fluentd.conf
```

### ç›‘æ§å’Œå‘Šè­¦

#### åŸºäºæ—¥å¿—çš„å‘Šè­¦

```bash
#!/bin/bash
# log-alert.sh

# åŸºäºæ—¥å¿—çš„å‘Šè­¦è„šæœ¬
LOG_FILE="/var/log/docker-alerts.log"
ALERT_KEYWORDS=("ERROR" "FATAL" "CRITICAL" "exception")

# ç›‘æ§æ—¥å¿—æ–‡ä»¶
tail -f /var/lib/docker/containers/*/*.log | while read line; do
    for keyword in "${ALERT_KEYWORDS[@]}"; do
        if echo "$line" | grep -q "$keyword"; then
            echo "$(date): å‘Šè­¦ - å‘ç°å…³é”®è¯ '$keyword'" | tee -a $LOG_FILE
            # å‘é€å‘Šè­¦é€šçŸ¥
            # curl -X POST -H 'Content-type: application/json' \
            #   --data "{\"text\":\"å‘Šè­¦: $line\"}" \
            #   $SLACK_WEBHOOK_URL
        fi
    done
done
```

#### æ€§èƒ½å‘Šè­¦è„šæœ¬

```bash
#!/bin/bash
# performance-alert.sh

# æ€§èƒ½å‘Šè­¦è„šæœ¬
ALERT_THRESHOLD_CPU=85
ALERT_THRESHOLD_MEM=85

send_alert() {
    local message="$1"
    echo "ğŸš¨ å‘Šè­¦: $message" | tee -a /var/log/performance-alerts.log
    
    # å‘é€é‚®ä»¶å‘Šè­¦
    # echo "$message" | mail -s "æ€§èƒ½å‘Šè­¦" admin@example.com
}

# æ£€æŸ¥æ‰€æœ‰å®¹å™¨
docker stats --no-stream --format "table {{.Container}}\t{{.Name}}\t{{.CPUPerc}}\t{{.MemPerc}}" | \
while read line; do
    container=$(echo $line | awk '{print $1}')
    name=$(echo $line | awk '{print $2}')
    cpu=$(echo $line | awk '{print $3}' | sed 's/%//')
    mem=$(echo $line | awk '{print $4}' | sed 's/%//')
    
    # è·³è¿‡æ ‡é¢˜è¡Œ
    if [[ "$container" == "CONTAINER" ]]; then
        continue
    fi
    
    # æ£€æŸ¥ CPU ä½¿ç”¨ç‡
    if (( $(echo "$cpu > $ALERT_THRESHOLD_CPU" | bc -l) )); then
        send_alert "å®¹å™¨ $name (ID: $container) CPU ä½¿ç”¨ç‡è¿‡é«˜: ${cpu}%"
    fi
    
    # æ£€æŸ¥å†…å­˜ä½¿ç”¨ç‡
    if (( $(echo "$mem > $ALERT_THRESHOLD_MEM" | bc -l) )); then
        send_alert "å®¹å™¨ $name (ID: $container) å†…å­˜ä½¿ç”¨ç‡è¿‡é«˜: ${mem}%"
    fi
done
```

### æ—¥å¿—å’Œè¯Šæ–­æœ€ä½³å®è·µ

#### æ—¥å¿—ç®¡ç†æœ€ä½³å®è·µ

1. **ç»“æ„åŒ–æ—¥å¿—**ï¼š
   - ä½¿ç”¨ JSON æ ¼å¼è®°å½•æ—¥å¿—
   - åŒ…å«æ—¶é—´æˆ³ã€çº§åˆ«ã€æœåŠ¡åç­‰å…ƒæ•°æ®

2. **æ—¥å¿—çº§åˆ«ç®¡ç†**ï¼š
   - åˆç†ä½¿ç”¨ä¸åŒçš„æ—¥å¿—çº§åˆ«
   - ç”Ÿäº§ç¯å¢ƒé¿å…è¿‡å¤šè°ƒè¯•æ—¥å¿—

3. **æ—¥å¿—è½®è½¬ç­–ç•¥**ï¼š
   - é…ç½®é€‚å½“çš„æ—¥å¿—å¤§å°é™åˆ¶
   - è®¾ç½®åˆç†çš„ä¿ç•™æ–‡ä»¶æ•°é‡

#### è¯Šæ–­å·¥å…·ä½¿ç”¨å»ºè®®

1. **å·¥å…·é€‰æ‹©**ï¼š
   - æ ¹æ®éœ€æ±‚é€‰æ‹©åˆé€‚çš„å·¥å…·
   - ç»“åˆå¤šç§å·¥å…·è¿›è¡Œå…¨é¢è¯Šæ–­

2. **è‡ªåŠ¨åŒ–ç›‘æ§**ï¼š
   - è®¾ç½®è‡ªåŠ¨åŒ–çš„ç›‘æ§å’Œå‘Šè­¦
   - å®šæœŸç”Ÿæˆè¯Šæ–­æŠ¥å‘Š

3. **æ€§èƒ½ä¼˜åŒ–**ï¼š
   - å®šæœŸåˆ†ææ—¥å¿—å’Œæ€§èƒ½æ•°æ®
   - æ ¹æ®åˆ†æç»“æœä¼˜åŒ–ç³»ç»Ÿé…ç½®

é€šè¿‡æœ¬èŠ‚å†…å®¹ï¼Œæˆ‘ä»¬æ·±å…¥äº†è§£äº† Docker çš„æ—¥å¿—ä¸è¯Šæ–­å·¥å…·ä½¿ç”¨æ–¹æ³•ï¼ŒåŒ…æ‹¬æ—¥å¿—ç®¡ç†ã€è¯Šæ–­å·¥å…·ã€æ€§èƒ½ç›‘æ§ã€è‡ªå®šä¹‰è„šæœ¬ç­‰æ–¹é¢ã€‚æŒæ¡è¿™äº›å·¥å…·å’ŒæŠ€å·§å°†å¸®åŠ©æ‚¨æ›´å¥½åœ°ç›‘æ§å’Œç»´æŠ¤å®¹å™¨åŒ–åº”ç”¨ï¼Œç¡®ä¿ç³»ç»Ÿçš„ç¨³å®šæ€§å’Œå¯é æ€§ã€‚